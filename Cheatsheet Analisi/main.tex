\documentclass{article}
\usepackage{multicol}
\usepackage{amsfonts}
\usepackage{commath}

\setlength{\parindent}{0pt}

\title{Cheatsheet Analisi}
\author{Angelo Passarelli}
\date{\today}

\begin{document}

\maketitle

\section{Forme Indeterminate}

\begin{multicols}{2}
    \begin{itemize}
        \item $\infty - \infty$
        \item $0 \cdot \infty$
        \item $\frac{0}{0}$
        \item $\frac{\infty}{\infty}$
        \item $1^\infty$
        \item $0^0$
        \item $\infty^0$
    \end{itemize}
\end{multicols}

\section{Limiti}

\subsection{Limiti Fondamentali}

\begin{multicols}{2}
    \begin{itemize}
        \item $\displaystyle \lim_{x \to + \infty} x = + \infty$
        \item $\displaystyle \lim_{x \to + \infty} x^n = + \infty$
        \item $\displaystyle \lim_{x \to + \infty} \frac{1}{x^n} = 0$
        \item $\displaystyle \lim_{x \to + \infty} e^x = + \infty$
        \item $\displaystyle \lim_{x \to - \infty} e^x = 0^+$
        \item $\displaystyle \lim_{x \to + \infty} \log x = + \infty$
        \item $\displaystyle \lim_{x \to 0^+} \log x = - \infty$
        \item $\displaystyle \lim_{x \to + \infty} a^x = + \infty \; se \; a > 1$
        \item $\displaystyle \lim_{x \to + \infty} a^x = 1 \; se \; a = 1$
        \item $\displaystyle \lim_{x \to + \infty} a^x = 0^+ \; se \; a < 1$
        \item $\displaystyle \lim_{x \to - \infty} a^x = 0^+ \; se \; a > 1$
        \item $\displaystyle \lim_{x \to - \infty} a^x = 1 \; se \; a = 1$
        \item $\displaystyle \lim_{x \to - \infty} a^x = + \infty \; se \; 0 < a < 1$
        \item $\displaystyle \lim_{x \to + \infty} x^a = + \infty \; se \; a > 0$
        \item $\displaystyle \lim_{x \to + \infty} x^a = 1 \; se \; a = 0$
        \item $\displaystyle \lim_{x \to + \infty} x^a = 0^+ \; se \; a < 0$
        \item $\displaystyle \lim_{x \to + \infty} \frac{a^x}{x^a} = + \infty \; se \; a > 1$
        \item $\displaystyle \lim_{x \to + \infty} \frac{a^x}{x^a} = 0^+ \; se \; 0 < a < 1$
        \item $\displaystyle \lim_{x \to x_0} f(x)^{g(x)} = \lim_{x \to x_0} e^{g(x) \cdot log(f(x))}$
    \end{itemize}
\end{multicols}

\newpage

\subsection{Limiti Notevoli}

\begin{multicols}{2}
    \begin{itemize}
        \item $\displaystyle \lim_{x \to 0} \frac{\sin x}{x} = 1$
        \item $\displaystyle \lim_{x \to 0} \frac{1 - \cos x}{x^2} = \frac{1}{2}$
        \item $\displaystyle \lim_{x \to 0} \frac{e^x - 1}{x} = 1$
        \item $\displaystyle \lim_{x \to 0} \frac{\log(1 + x)}{x} = 1$
    \end{itemize}
\end{multicols}

\section{Proprietà degli Infinitesimi}

\begin{enumerate}
    \item $f(x) \cdot o(g(x)) = o(f(x) \cdot g(x))$
    \item $o(k \cdot g) = o(g)$, con $k \in \mathbb{R}, \; k \neq 0$
    \item $o(g) + o(g) = o(g)$
    \item Se $\displaystyle \lim_{x \to x_0} f(x) = 0$, allora $f(x) \cdot g(x) = o(g)$
    \item Se $\displaystyle \lim_{x \to x_0} f(x) = 0$, allora $o(g) + o(f \cdot g) = o(g)$
    \item $o(o(g)) = o(g)$
    \item $o(f + g) = o(f) + o(g)$
    \item $o(g) \cdot o(f) = o(g \cdot f)$
\end{enumerate}

\section{Sviluppi al 1°/2° ordine}

\begin{multicols}{2}
    \begin{itemize}
        \item $\sin x = x + o(x^2)$
        \item $\cos x = 1 - \frac{x^2}{2} + o(x^2)$
        \item $e^x = 1 + x + o(x)$
        \item $\log(1 + x) = x + o(x)$
        \item $\tan x = x + o(x)$
        \item $\arctan x = x + o(x^2)$
        \item $(1 + x)^\alpha = 1 + \alpha x + o(x)$
    \end{itemize}
\end{multicols}

\section{Derivate}

\begin{itemize}
    \item $D(x) = 1$
    \item $D(x^n) = n \cdot x^{n - 1}$
    \item $D(\sin x) = \cos x$
    \item $D(\cos x) = - \sin x$
    \item $D(\tan x) = D(\frac{\sin x}{\cos x}) = 1 + \tan^2 x$ oppure $\frac{1}{\cos^2 x}$
    \item $D(\sqrt{x}) = D(x^{\frac{1}{2}}) = \frac{1}{2 \cdot \sqrt{x}}$
    \item $D(log_ax) = \frac{1}{x \cdot \log a}$
    \item $D(a^x) = D(e^{x \cdot \log a}) = a^x \cdot \log a$
    \item $D(f^{-1}(x)) = \frac{1}{D(f(f^{-1}(x)))}$
    \item $D(\arctan x) = \frac{1}{1 + x^2}$
    \item $D(f(x) \cdot g(x)) = D(f(x)) \cdot g(x) + f(x) \cdot D(g(x))$
    \item $D(\frac{f(x)}{g(x)}) = \frac{D(f(x)) \cdot g(x) - D(g(x)) \cdot f(x)}{g(x)^2}$
\end{itemize}

\section{Serie di Taylor con resto di Peano}

\begin{itemize}
    \item $\displaystyle \sin x = (\sum_{j=0}^{n} \frac{(-1)^j \cdot x^{2j + 1}}{(2j + 1)!}) + o(x^{2n + 2})$
    \item $\displaystyle \cos x = (\sum_{j=0}^{n} \frac{(-1)^j \cdot x^{2j}}{(2j)!}) + o(x^{2n + 1})$
    \item $\displaystyle \log(1 + x) = (\sum_{j=1}^{n} (-1)^{j+1} \cdot \frac{x^j}{j}) + o(x^n)$
    \item $\displaystyle e^x = (\sum_{j = 0}^{n} \frac{x^j}{j!}) + o(x^n)$
    \item $\displaystyle \arctan x = (\sum_{j=0}^{n} (-1)^j \cdot \frac{x^{2j + 1}}{2j + 1}) + o(x^{2n + 2})$
    \item $\displaystyle (1 + x)^a = 1 + ax + \frac{a(a - 1)}{2}x^2 + \frac{a(a - 1)(a - 2)}{3!}x^3 + \frac{a(a - 1)(a - 2) \dots (a - n + 1)}{n!}x^n + o(x^n)$
\end{itemize}

\section{Integrali di Riemann}

\subsection{Primitive Notevoli}

\begin{multicols}{2}
    \begin{enumerate}
        \item $\int e^x \; dx = e^x + k$
        \item $\int \cos x \; dx = \sin x + k$
        \item $\int \sin x \; dx = -\cos x + k$
        \item $\int \frac{1}{1 + x^2} \; dx = \arctan(x) + k$
        \item $\int \frac{1}{x} \; dx = \log \abs{x} + k$
        \item $\int x^n \; dx = \frac{1}{n + 1} \cdot x^{n + 1} + k$
        \item $\int \frac{1}{\sqrt{1 - x^2}} \; dx = \arcsin(x) + k$
    \end{enumerate}
\end{multicols}

\subsection{Teorema di Torricelli}

\begin{equation*}
    \int_{\alpha}^\beta f(t) \; dt = [G(x)]_{\alpha}^\beta = G(\beta) - G(\alpha)
\end{equation*}

\subsection{Integrali con estremi variabili}

\begin{equation*}
    G(x) = \int_{\alpha(x)}^{\beta(x)} f(t) \; dt
\end{equation*}

\begin{equation*}
    G'(x) = f(\beta(x)) \cdot \beta'(x) - f(\alpha(x)) \cdot \alpha'(x)
\end{equation*}

\subsection{Integrazione per parti}

\begin{equation*}
    \int{f \cdot g} \; dx = F \cdot g - \int{F \cdot g'} \; dx
\end{equation*}

\subsection{Integrazione per sostituzione}

\begin{equation*}
    \int (f \circ \varphi) \cdot \varphi' \; dx = (F \cdot \varphi) + k
\end{equation*}

\subsection{Integrali di funzioni razionali}

\begin{itemize}
    \item $q(x)$ con grado 1:
        \begin{equation*}
            \int \frac{1}{ax + b} \; dx = \frac{1}{a} \log{\abs{ax + b}} + k
        \end{equation*}
    \item Se il grado di $p(x) > 0$ si fa la divisione per $q(x)$ utilizzando Ruffini.
    \item Se $q(x)$ ha grado $2$:
        \begin{enumerate}
            \item Due radici uguali e numeratore costante:
            \begin{equation*}
                \int \frac{dx}{(x - a)^2} = -\frac{1}{x - a} + k
            \end{equation*}
            \item Due radici diverse e numeratore costante:
            \begin{equation*}
                \int \frac{dx}{(x - a)(x - b)} = \frac{1}{a - b} \cdot \log{\abs{\frac{x - a}{x - b}}} + k
            \end{equation*}
            \item Denominatore senza radici reali e numeratore costante:
                \begin{equation*}
                    \int \frac{dx}{k^2 + x^2} = \frac{1}{k} \cdot \arctan(\frac{x}{k}) + c
                \end{equation*}
                \begin{equation*}
                    \int \frac{1}{ax^2 + bx + c} \; dx = \frac{1}{a} \cdot \int \frac{1}{x^2 + \frac{b}{a}x + \frac{c}{a}}
                \end{equation*}
                Supponendo che $a = 1$:
                \begin{equation*}
                    x^2 + bx + c = (x^2 + bx + \frac{b^2}{4}) - \frac{b^2}{4} + c =
                \end{equation*}
                \begin{equation*}
                    = (x + \frac{b}{2})^2 + \frac{1}{4}(-b^2 + 4c)
                \end{equation*}
                Poniamo $k^2 = \frac{1}{4}(-b^2 + 4c) > 0$
                \begin{equation*}
                    \int \frac{1}{ax^2 + bx + c} \; dx = \int \frac{dx}{(x + \frac{b}{2})^2 + k^2} = \frac{1}{k} \cdot \arctan(\frac{x + \frac{b}{2}}{k}) + c
                \end{equation*}
        \end{enumerate}
    \item Numeratore non costante, con grado uguale a $1$:
        \begin{equation*}
            \int \frac{ax + b}{x^2 + cx + d} \; dx = \frac{a}{2} \cdot \log{\abs{x^2 + cx + d}} + \frac{a}{2} \cdot \int{\frac{-c + \frac{2b}{a}}{x^2 + cx + d}} dx
        \end{equation*}
\end{itemize}

\section{Integrali Impropri}

\subsection{Calcolo}

\begin{equation*}
    \int_{a}^b f(x) \; dx = \lim_{M \to b^-} \int_{a}^M f(x) \; dx = L
\end{equation*}

Se $L$ é:

\begin{itemize}
    \item Finito, l'integrale diverge in senso generalizzato su $[a, b)$.
    \item $+ \infty$, l'integrale diverge positivamente su $[a, b)$.
    \item $- \infty$, l'integrale diverge negativamente su $[a, b)$.
\end{itemize}

\subsection{Integrali Impropri Notevoli}

\begin{equation*}
    \int_{a}^{+ \infty} \frac{1}{x^\alpha} \; dx, \; \alpha \in \mathbb{R}
\end{equation*}

\begin{itemize}
    \item Se $\displaystyle \alpha = 1, \int \frac{1}{x} \; dx = \log{\abs{x}} \rightsquigarrow \lim_{M \to + \infty} [\log{\abs{x}}]_{1}^M = + \infty$
    \item Se $\displaystyle \alpha \neq 1, \int \frac{1}{x^\alpha} \; dx = \frac{1}{1 - \alpha} x^{1 - \alpha} + c \rightsquigarrow \lim_{M \to + \infty} [\frac{x^{1-\alpha}}{1 - \alpha}]_{1}^M = \frac{1}{1 - \alpha} \cdot M^{1 - \alpha} - \frac{1}{1 - \alpha}$
        \begin{itemize}
            \item[-] Se $1 -\alpha > 0$, $\alpha < 1$, il limite é $+ \infty$.
            \item[-] Se $1 -\alpha < 0$, $\alpha > 1$, il limite é finito ed é $\frac{1}{1 - \alpha} > 0$. 
        \end{itemize}
\end{itemize}

\begin{equation*}
    \int_{0}^1 \frac{1}{x^\alpha} \; dx, \; \alpha \in \mathbb{R}
\end{equation*}

\begin{itemize}
    \item Se $\displaystyle \alpha = 1, \int \frac{1}{x} \; dx = \log{\abs{x}} \rightsquigarrow \lim_{M \to 0^+} [\log{\abs{x}}]_{M}^1 = + \infty$
    \item Se $\displaystyle \alpha \neq 1, \int_{0}^1 \frac{1}{x^\alpha} \; dx = \lim_{M \to 0^+} [\frac{x^{1-\alpha}}{1 - \alpha}]_{M}^1 =  \lim_{M \to 0^+} \frac{1}{1 - \alpha} - \frac{1}{1 - \alpha} \cdot M^{1 - \alpha}$
        \begin{itemize}
            \item[-] Se $1 -\alpha > 0$, $\alpha < 1$, il limite é finito ed é $\frac{1}{1 - \alpha} > 0$.
            \item[-] Se $1 -\alpha < 0$, $\alpha > 1$, il limite é $+ \infty$. 
        \end{itemize}
\end{itemize}

\subsection{Criterio del Confronto}

Date due funzioni $f,g: [a, b)$, se esiste un intorno di b dove $0<f(x)<g(x)$:

\begin{enumerate}
    \item Se $\int_{a}^b g(x)$ converge, allora anche $\int_{a}^b f(x)$ converge.
    \item Se $\int_{a}^b f(x)$ diverge, allora anche $\int_{a}^b g(x)$ diverge. 
\end{enumerate}

\subsection{Criterio del Confronto Asintotico}

Date due funzioni $f,g: [a, b)$, se esiste un intorno di b dove $f(x) \geq 0, \; g(x) \geq 0$, ed esiste $\displaystyle \lim_{x \to b^-} \frac{f(x)}{g(x)} = l$, allora:

\begin{itemize}
    \item Se $l \neq 0, \; l \neq + \infty$, allora $\int_{a}^b f(x) dx$ converge $\Leftrightarrow \int_{a}^b g(x) dx$ converge.
    \item Se $l = 0$, allora $\int_{a}^b g(x) dx$ converge $\Rightarrow \int_{a}^b f(x) dx$ converge.
    \item Se $l = + \infty$, allora $\int_{a}^b f(x) dx$ converge $\Rightarrow \int_{a}^b g(x) dx$ converge.
\end{itemize}

\subsection{Criterio dell'Assoluta Convergenza}

Se $\int_I{\abs{f(x)}} \; dx$ converge, allora anche $\int_I f(x) \; dx$ converge.

\section{Successioni}

\subsection{Limiti di Funzioni e Successioni}

Data una funzione $f: A \rightarrow \mathbb{R}$:

\begin{equation*}
    \displaystyle \lim_{x \to x_0} f(x) = l \Leftrightarrow \lim_{n \to x_0} f(a_n) = l \; se \; \forall \; \{a_n\} \subseteq A : \lim_{n \to + \infty} a_n = x_0 \; e \; a_n \neq x_0 \; definitivamente
\end{equation*}

\subsection{Sottosuccessioni}

Data $\{a_n\}$ e le sottosuccessioni $\{a_{k_n}\}$ e $\{a_{h_n}\}$ che partizionano tutto $\mathbb{N}$:

\begin{equation*}
    \displaystyle \lim_{x \to + \infty} a_{k_n} = l \; e \lim_{x \to + \infty} a_{h_n} = l \Rightarrow \lim_{x \to + \infty} a_n = l
\end{equation*}

\subsection{Criterio del Rapporto}

Se $\{a_n\} > 0$ definitivamente ed esiste $\displaystyle \lim_{n \to + \infty} \frac{a_{n+1}}{a_n} = l$, allora:

\begin{enumerate}
    \item se $0 \leq l < 1$, allora $\displaystyle \lim_{n \to + \infty} a_n = 0$.
    \item se $l > 1$, allora $\displaystyle \lim_{n \to + \infty} a_n = + \infty$.
    \item se $l = 1$, il criterio non si applica.
\end{enumerate}

\subsection{Criterio della Radice}

Se $\{a_n\} > 0$ definitivamente ed esiste $\displaystyle \lim_{n \to + \infty} \sqrt[n]{a_n} = l$, allora:

\begin{enumerate}
    \item se $0 \leq l < 1$, allora $\displaystyle \lim_{n \to + \infty} a_n = 0$.
    \item se $l > 1$, allora $\displaystyle \lim_{n \to + \infty} a_n = + \infty$.
    \item se $l = 1$, il criterio non si applica.
\end{enumerate}

Se $a_n > 0$ definitivamente ed esiste $\displaystyle \lim_{n \to + \infty} \frac{a_{n+1}}{a_n} = l$, allora $\displaystyle \exists \lim_{n \to + \infty} \sqrt[n]{a_n} = l$.

\section{Serie}

\subsection{Serie Geometrica}

Dato $\alpha \in \mathbb{R}$, $\alpha \neq 0$ e una successione $a_n = \alpha^n$: \\ \\
$\displaystyle \sum_{n \in \mathbb{N}} a_n = \sum_{n \in \mathbb{N}} \alpha^n$. \\
$\displaystyle s_n = \sum_{j = 0}^n \alpha^j = 1 + \alpha + \alpha^2 + \dots + \alpha^n = \frac{\alpha^{n+1}-1}{\alpha-1}$. \\ \\
$\displaystyle \lim_{n \to + \infty} s_n$:

\begin{itemize}
    \item se $\abs{\alpha} < 1$, $\alpha^{n+1} \to 0$, $s_n = \frac{1}{1-\alpha}$, quindi la serie converge.
    \item se $\alpha > 1$, $\alpha^{n+1} \to + \infty$, quindi la serie diverge positivamente.
    \item se $\alpha = 1$, $a_n = 1^n = 1$, $\displaystyle \sum_{n \in \mathbb{N}} 1 = + \infty$, quindi la serie diverge positivamente.
    \item se $\alpha < -1$, $\alpha^{n+1}$ non ha limite:
    \begin{itemize}
        \item[-] se $n$ è pari ($n+1$ è dispari), $\alpha^{n+1} < 0$, quindi la sottosuccessione tende a $- \infty$.
        \item[-] se $n$ è dispari ($n+1$ è pari), quindi $\alpha^{n+1}$ tende a $+ \infty$. 
    \end{itemize}
\end{itemize}

\subsection{Condizione Necessaria}

\begin{equation*}
    \displaystyle \sum_{n} a_n \; non \; converge \; \Leftrightarrow \displaystyle \lim_{n \to + \infty} a_n \neq 0
\end{equation*}

\subsection{Criterio del Confronto}

Se $0 \leq a_n \leq b_n$ definitivamente, allora:

\begin{enumerate}
    \item se $\displaystyle \sum_{n} b_n$ converge $\Rightarrow \displaystyle \sum_{n} a_n$ converge.
    \item se $\displaystyle \sum_{n} a_n$ diverge $\Rightarrow \displaystyle \sum_{n} b_n$ diverge.
\end{enumerate}

\subsection{Criterio del Confronto Asintotico}

Date $\{a_n\}$, $\{b_n\}$ tali che $a_n > 0$, $b_n > 0$ definitivamente e $\displaystyle \lim_{n \to + \infty} \frac{a_n}{b_n} = l \in \mathbb{R}$, allora:

\begin{enumerate}
    \item se $l \in (0, + \infty)$, allora $\displaystyle \sum_n a_n$ e $\displaystyle \sum_n b_n$ hanno lo stesso comportamento.
    \item se $l = 0$, $\displaystyle \sum_n b_n \; converge \; \Rightarrow \sum_n a_n \; converge$.
    \item se $l = + \infty, \sum_n b_n \; diverge \; \Rightarrow \sum_n a_n \; diverge$.
\end{enumerate}

\subsection{Criterio della Radice per Serie}

Data $\{a_n\}$, $a_n > 0$ definitivamente, se $\exists \displaystyle \lim_{n \to + \infty} \sqrt[n]{a_n} = l \in \mathbb{R}$, allora:

\begin{enumerate}
    \item se $0 \leq l < 1 \Rightarrow \displaystyle \sum_n a_n$ converge.
    \item se $l > 1 \Rightarrow \displaystyle \sum_n a_n$ diverge.
    \item se $l = 1$ il criterio non si applica.
\end{enumerate}

\subsection{Criterio del Rapporto per Serie}

Data $\{a_n\}$, $a_n > 0$ definitivamente, se $\exists \displaystyle \lim_{n \to + \infty} \frac{a_{n+1}}{a_n} = l \in \mathbb{R}$, allora:

\begin{enumerate}
    \item se $0 \leq l < 1 \Rightarrow \displaystyle \sum_n a_n$ converge.
    \item se $l > 1 \Rightarrow \displaystyle \sum_n a_n$ diverge.
    \item se $l = 1$ il criterio non si applica.
\end{enumerate}

\subsection{Criterio dell'Integrale}

Dato un $\bar{n} \in \mathbb{N}$ e una funzione $f: [\bar{n}, + \infty] \to \mathbb{R}$ debolmente crescente, continua e con $f(x) \geq 0 \; \forall \; x \in [\bar{n}, + \infty]$: \\

\begin{equation*}
    \displaystyle Se \; a_n = f(n) \Rightarrow \sum_n a_n \; e \int_{\bar{n}}^{+ \infty} f(x) \; dx \; hanno \; lo \; stesso \; comportamento
\end{equation*}

\begin{equation*}
    e \; \sum_{n=\bar{n}+1}^{+ \infty} a_n \leq \int_{\bar{n}}^{+ \infty} f(x) \; dx \leq \sum_{n=\bar{n}}^{+ \infty} a_n
\end{equation*}

\subsection{Convergenza Assoluta - Serie a Segno Arbitrario}

$\displaystyle \sum_n a_n$ converge assolutamente se $\displaystyle \sum_n \; \abs{a_n}$ converge. \\
Se $\displaystyle \sum_n a_n$ converge assolutamente $\Rightarrow$ converge e $\displaystyle \abs{\sum_n a_n} \leq \sum_n \; \abs{a_n}$.

\subsection{Criterio di Leibniz - Serie a Segno Alterno}

Se $\{a_n\} \geq 0$ definitivamente, è debolmente decrescente e $\displaystyle \lim_{n \to + \infty} a_n = 0$, \\
allora $\displaystyle \sum_n (-1)^n a_n$ converge e $\displaystyle \abs{\sum_{j=0}^{+ \infty} (-1)^j a_j - \sum_{j=0}^{n} (-1)^j a_j} \leq a_{n+1}$.

\section{Calcolo Differenziale in 2 Variabili}

\subsection{Prodotto scalare}

$x = (x_1, \dots, x_n)$. \\
$y = (y_1, \dots, y_n)$. \\ \\
$\langle x, y \rangle = x \cdot y = (x, y) = x_1y_1 + x_2y_2 + \dots x_ny_n$.

\subsection{Norma}

$x = (x_1, \dots, x_n)$. \\ \\
$\lVert x \rVert = \abs{x} = \sqrt{\langle x, x \rangle} = \sqrt{x_1^2 + x_2^2 + \dots x_n^2} \rightarrow$ lunghezza del vettore $x$. 

\subsection{Distanza}

$x = (x_1, \dots, x_n)$. \\
$y = (y_1, \dots, y_n)$. \\ \\
$dist(x, y) = d(x, y) = \lVert x - y \rVert = \sqrt{(x_1 - y_1)^2 + \dots + (x_n - y_n)^2} \rightarrow$ differenza tra $x$ e $y$.

\subsection{Retta passante per 2 punti in $\mathbb{R}^2$}

$P_1 = (x_1, y_1) = v$. \\
$P_2 = (x_2, y_2) = w$. \\
Vettore Direzione = Vettore Differenza: $u = w - v$.

\paragraph{Forma Parametrica}

\begin{equation*}
    r : \{ 
    \begin{pmatrix}
        x \\
        y
    \end{pmatrix} =
    \begin{pmatrix}
        x_1 \\
        y_2
    \end{pmatrix} + t
    \begin{pmatrix}
        x_2 - x_1 \\
        y_2 - y2
    \end{pmatrix}
    \}
\end{equation*}

\paragraph{Forma Cartesiana}

\begin{equation*}
    r: \frac{x - x_1}{x_2 - x_1} = \frac{y - y_1}{y_2 - y_1}
\end{equation*}

\subsection{Retta perpendicolare a $v$ passante per l'origine}

$v = (a, b)$. \\
$v \perp w \Leftrightarrow \; <v, w> \; = 0$. \\
Quindi $<(a, b), (w_1, w_2)> \; = 0 \Rightarrow a \cdot w_1 + b \cdot w_2 = 0$. \\
Per far rispettare l'uguaglianza, $w_2$ e $w_1$ devono assumere i seguenti valori: \\
$w_1 = -b$. \\
$w_2 = a$. \\
$w = (-b, a)$.

\paragraph{Forma Parametrica}

\begin{equation*}
    r: \{
    \begin{pmatrix}
        x \\
        y
    \end{pmatrix} = t
    \begin{pmatrix}
        -b \\
        a
    \end{pmatrix}
    \}
\end{equation*}

\paragraph{Forma Cartesiana}

\begin{equation*}
    r: ax + by = 0
\end{equation*}

\subsection{Retta tangente ad 1 grafico}

Data una funzione $f: \mathbb{R} \to \mathbb{R}$ continua, derivabile e con derivate continue, vogliamo trovare la retta tangente al grafico nel punto $(x_0, y_0)$.

\paragraph{Forma Parametrica}

\begin{equation*}
    r: \{
    \begin{pmatrix}
        x \\
        y
    \end{pmatrix} =
    \begin{pmatrix}
        x_0 \\
        y_0
    \end{pmatrix} + t
    \begin{pmatrix}
        1 \\
        f'(x_0)
    \end{pmatrix}
    \}
\end{equation*}

\paragraph{Forma Cartesiana}

\begin{equation*}
    r: y = f(x_0) + f'(x_0)(x - x_0)
\end{equation*}

\subsection{Retta passante per 2 punti in $\mathbb{R}^3$}

$P_1 = (x_1, y_1, z_1) = v$. \\
$P_2 = (x_2, y_2, z_2) = w$. \\
Vettore Direzione = Vettore Differenza: $u = w - v$.

\paragraph{Forma Parametrica}

\begin{equation*}
    r: \{
    \begin{pmatrix}
        x \\
        y \\
        z
    \end{pmatrix} =
    \begin{pmatrix}
        x_1 \\
        y_1 \\
        z_1
    \end{pmatrix} + t
    \begin{pmatrix}
        x_2 - x_1 \\
        y_2 - y_1 \\
        z_2 - z_1
    \end{pmatrix}
    \}
\end{equation*}

\paragraph{Forma Cartesiana}

\begin{equation*}
    \begin{cases}
        \frac{x - x_1}{x_2 - x_1} = \frac{y - y_1}{y_2 - y_1} \rightarrow 1 \; piano \\
        \frac{y - y_1}{y_2 - y_1} = \frac{z - z_1}{z_2 - z_1} \rightarrow 1 \; piano \\
    \end{cases}
\end{equation*}

L'intersezione dei due piani risultanti dal sistema costituisce una retta.

\subsection{Piano passante per 3 punti in $\mathbb{R}^3$}

$P_1 = (x_1, y_1, z_1) = u$. \\
$P_2 = (x_2, y_2, z_2) = v$. \\
$P_3 = (x_3, y_3, z_3) = w$. \\
Vettore Direzione 1: $P_2 - P_1 = v - u$. \\
Vettore Direzione 2: $P_3 - P_1 = w - u$.

\paragraph{Forma Parametrica}

\begin{equation*}
    \pi : \{
    \begin{pmatrix}
        x \\
        y \\
        z
    \end{pmatrix} =
    \begin{pmatrix}
        x_1 \\
        y_1 \\
        z_1
    \end{pmatrix} + t
    \begin{pmatrix}
        x_2 - x_1 \\
        y_2 - y_1 \\
        z_2 - z_1
    \end{pmatrix} + s
    \begin{pmatrix}
        x_3 - x_1 \\
        y_3 - y_1 \\
        z_3 - z_1
    \end{pmatrix}
    \}
\end{equation*}

\paragraph{Forma Cartesiana}

\begin{equation*}
    \pi : \frac{(\frac{x - x_1}{x_2 - x_1} - \frac{y - y_1}{y_2 - y_1})}{(\frac{x_3 - x_1}{x_2 - x_1} - \frac{y_3 - y_1}{y_2 - y_1})} = \frac{(\frac{x - x_1}{x_2 - x_1} - \frac{z - z_1}{z_2 - z_1})}{(\frac{x_3 - x_2}{x_2 - x_1} - \frac{z_3 - z_1}{z_2 - z_1})}
\end{equation*}

\subsection{Curve}

\subsubsection{Vettore Tangente}

Data una curva $\gamma: I \to \mathbb{R}^2$ il vettore tangente alla curva è:

\begin{equation*}
    \overset{\bullet}{\gamma}(t) = \gamma'(t) = (x'(t), y'(t))
\end{equation*}

\subsubsection{Retta Tangente}

\begin{equation*}
    r: \gamma(t) + s \; \overset{\bullet}{\gamma}(t)
\end{equation*}

\subsection{Limiti}

\subsubsection{Metodo delle Coordinate Polari}

\begin{equation*}
    \begin{cases}
        x = x_0 + \rho \cos \Theta \\
        y = y_0 + \rho \sin \Theta
    \end{cases}
\end{equation*}

\subsubsection{Limiti all'Infinito}

\begin{equation*}
    (x, y) \to \infty \Leftrightarrow 
    \begin{cases}
        x^2 + y^2 \to +\infty \\
        d((x, y), (0, 0)) \to +\infty \\
        \rho \to +\infty
    \end{cases}
\end{equation*}

\subsection{Derivate Parziali}

\subsubsection{Verificare la derivabilità in un punto}

Dato un punto $v$ (vettore), per verificare che la funzione sia derivabile in quel punto nella direzione data dal vettore $(\alpha, \beta)$:

\begin{equation*}
    \displaystyle \lim_{t \to 0} \frac{f(v + t(\alpha, \beta)) - f(v)}{t}
\end{equation*}

\subsection{Parametrizzazione del Bordo}

\begin{enumerate}
    \item \textbf{Segmento di estremi} ($a_1$, $b_1$) e ($a_2$, $b_2$)
        \begin{equation*}
            (x, y) = (a_1, b_1) + t(a_2 - a_1, b_2 - b_1) \; \; \; t \in [0, 1] 
        \end{equation*}
    \item \textbf{Tratto del grafico}
        $y = \varphi(x)$ con $x \in [a, b]$
        \begin{equation*}
            (x, y) = (t, \varphi(t)) \; \; \; t \in [a, b]
        \end{equation*}
    \item \textbf{Circonferenza} di raggio $r$ e centro $(x_0, y_0)$
        \begin{equation*}
            (x, y) = (r \cdot \cos \Theta, r \cdot \sin \Theta) \; \; \; \Theta \in [0, 2\pi]
        \end{equation*}
    \item \textbf{Ellisse} di equazione $ax^2 + by^2 = 1$ con $a, b > 0$
        \begin{equation*}
            (x, y) = (\frac{1}{\sqrt{a}} \cdot \cos \Theta, \frac{1}{\sqrt{b}} \cdot \sin \Theta) \; \; \; \Theta \in [0, 2\pi]
        \end{equation*}
\end{enumerate}

\subsection{Metodo dei Moltiplicatori di Lagrange}

$\Phi(x, y)$ è il luogo degli zeri (bordo) dell'insieme su cui è definita la funzione $f(x, y)$.

\begin{equation*}
    \begin{split}
        S1 & \begin{cases}
            \Phi(x, y) = 0 \\
            \nabla \Phi(x, y) = 0
        \end{cases} \\
        S2 & \begin{cases}
            \Phi(x, y) = 0 \\
            \nabla f(x, y) = \lambda \nabla \Phi(x, y)
        \end{cases}
    \end{split}    
\end{equation*}

\end{document}